name: Daily Pool Scraper

on:
  schedule:
    # Läuft täglich um 02:00 UTC (3:00 CET)
    - cron: '0 2 * * *'
  # Optional: manuell triggern für Tests
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run scraper
        run: |
          python scraper/scrape_pools.py --file urls.txt
          # Prüfe ob data/pools.json valid JSON ist
          python -m json.tool data/pools.json > /dev/null

      - name: Commit & push (if changed)
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          
          # Nur committen wenn data/pools.json sich geändert hat
          if git diff --quiet data/pools.json; then
            echo "No changes to data/pools.json, skipping commit"
          else
            git add data/pools.json
            git commit -m "chore: update pools.json ($(date -u +'%Y-%m-%d %H:%M UTC'))"
            git push
          fi
